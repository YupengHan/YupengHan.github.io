<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-149845984-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-149845984-1');
</script>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Yupeng HAN's Research Interests </title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">MENU</div>
<div class="menu-item"><a href="index.html" class="current">Yupeng Han</a></div>
<div class="menu-item"><a href="randp.html">Research & Projects</a></div>
<!-- <div class="menu-item"><a href="new_research_project.html"> <b>[New]</b> Ongoing Project</a></div> -->
<div class="menu-item"><a href="edu.html">Education</a></div>
<div class="menu-item"><a href="activities.html">Activities</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<!-- Learning-Free Object Detection and Localization -->
<h1><BIG>L</BIG><small>EARNING-</small> <BIG>F</BIG><small>REE</small> <BIG>O</BIG><small>BJECT</small> <BIG>D</BIG><small>ETECTION</small> <BIG>A</BIG><small>ND</small> <BIG>L</BIG><small>OCALIZATION</small></h1>
</div>
<table class="imgtable"><tr><td>
  <img src="photos/NPJ_Overview.png" alt="alt text" width="609px" height="330px" />&nbsp;</td>
  </tr></table>
<h1><BIG>M</BIG><small>OTIVATION</small></h1>
Intelligent warehouse is a promising area, and predicting object poses is a critical task.

<table class="imgtable"><tr><td>
  <img src="photos/NPJ_motiv.png" alt="alt text" width="385px" height="321px" />&nbsp;</td>
  <td align="left">
    <br>In the scenario of smart warehousing, it generally has the following characteristics: </br>
    <ul>
      <li><p>Known object</p></li>  
      <li><p>Object types often change</p></li>  
      <li><p>Each warehouse has different conditions (lighting, object types)</p></li>  
    </ul>
  </td>
</tr></table>




<br>Current mainstream object detection and location approaches rely on neural networks, which may have the following problems:</br>
<ul>
  <li><p>[1] For each new scenario, a corresponding training data set needs to be established (Which could be expensive, especially for 6DOF pose labeling).</p></li>
  <li><p>[2] When there is a change in the scene (Eg: the light becomes stronger), it is necessary to <b>RE-establish</b> the data set and <b>RE-train</b> a new neural network.</p></li>
</ul>
<h3>Observation</h3>
I revisited the way neural networks recognize objects.<br />
<ul>
  <li><p>[1] Color information, provided by RGB images and label data.</p></li>
  <li><p>[2] Pattern information, that is, the surface texture information of the object of interest.</p></li>
</ul>
<table class="imgtable"><tr><td>
  <img src="photos/The_Dress2.png" alt="alt text" width="555px" height="263px" />&nbsp;</td>
  <!-- <td align="left">
    The dress is a photograph that <br/>
    became a viral internet sensation <br/>
    on 26 February 2015,<br/>
    when viewers disagreed over <br/>
    whether the dress pictured was <br/>
    coloured black and royal blue,<br/>
    or white and gold.<br/>
    [<a href="https://en.wikipedia.org/wiki/The_dress">Wikipedia The Dress</a>]
  </td> -->
</tr></table>
  
  
<!-- In my opinion, the reason why the current mainstream object recognition algorithms lack portability is that <br />
<ul>
  [1] Without a given white point, there is no one-to-one correspondence between the RGB color information and the actual hue of the object.<br />
  [2] It is worth noting that humans do not directly use RGB information but use the brain to process RGB information.
</ul> -->
Through further understanding, I found that the colors we usually talk about can be divided into hue, saturation, and luminance. <br />
Interestingly, in different luminance situations, different hues may show the same RGB. <br />
<table class="imgtable"><tr><td>
  &emsp;&emsp;<img src="photos/rgb_1.png" alt="alt text" width="535px" height="250px" />&nbsp;</td>
  </tr></table>
<!-- <h3>Limitation</h3>
This has a major impact on neural networks. If we are in an environment where the light intensity is A, collect data and train CNN. When the test environment light intensity B and A are very different, we can hardly expect CNN to have the same accuracy as in the past. -->

<!-- Proposed Approach -->
<h1><BIG>P</BIG><small>ROPOSED</small> <BIG>A</BIG><small>PPROACH</small></h1>
<table class="imgtable"><tr><td>
  <img src="photos/NPG_pipe.png" alt="alt text" width="300px" height="300px" />&nbsp;</td>
  <td align="left">
    <br>In order to solve the above-mentioned problems, we propose an object detection method based on RGB-D data and object 3D model.</br>
    <ul>
      <li><p>Our method first rendering different object poses in the scene, comparing the rendered synthesis point cloud with the collected observed point cloud, and selecting the most similar pose as the predict pose.</p></li>
      <li><p>Unlike other learning-based approaches, it does not require a training process. For new scenes, we can scan the object through the RGB-D sensor to build new 3D model of the object under the new lighting condition.</p></li>
      <li><p>For light-stable scenes (EG: warehouses), this type of method is quick and easy to implement.</p></li>
    </ul>
  </td>
</tr></table>


<!-- In order to solve the above-mentioned problems, we propose an object detection method based on RGB-D data and object 3D model.
<ul>
  <li><p>Our method first rendering different object poses in the scene, comparing the rendered synthesis point cloud with the collected observed point cloud, and selecting the most similar pose as the predict pose.</p></li>
  <li><p>Unlike other learning-based approaches, it does not require a training process. For new scenes, we can scan the object through the RGB-D sensor to build new 3D model of the object under the new lighting condition.</p></li>
  <li><p>For light-stable scenes (EG: warehouses), this type of method is quick and easy to implement.</p></li>
</ul> -->

<h1><BIG>O</BIG><small>NGOING</small> <BIG>P</BIG><small>ROJECT</small></h1>
<h3>Build New Object 3D Model</h3>
<div>
  <video id = "cg1" autobuffer playsinline muted width="384" height="216" autobuffer class="video-background" controls>
      <source src="gifs/get_model_1.mp4" type="video/mp4">
    Your browser does not support the video tag.
    </video>
  <script>
      document.getElementById('cg1').play();
  </script>
  &nbsp&nbsp
  <video id = "cg2" autobuffer playsinline muted autoplay="autoplay" loop="loop" width="384" height="216" controls>
    <source src="gifs/get_model_2.mp4" type="video/mp4">
      Your browser does not support the video tag.
  </video>
  <script>
      document.getElementById('cg2').play();
  </script>
  </div>
<h3>Collect RGB-D Data</h3>
  <video autoplay loop muted playsinline  width="597" height="261" autobuffer class="video-background" controls>
    <source src="photos/NPJ_RGBD_1.mp4" type="video/mp4">
  Your browser does not support the video tag.
  </video>
<h3>[Interesting Topics] Geometry Representation</h3>
Along with the research, since we were always chasing real-time performance, describing geometry information efficiently is an essential task for us.
<table class="imgtable"><tr><td>
  <img src="photos/NPJ_geo.png" alt="alt text" width="729px" height="317px" />&nbsp;</td>
</tr></table>