<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-149845984-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-149845984-1');
</script>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Yupeng HAN's Research Interests </title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">MENU</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html" class="current">Research</a></div>
<div class="menu-item"><a href="new_research_project.html"> <b>[New]</b> Research Project</a></div>
<div class="menu-item"><a href="projects.html">Selected Projects</a></div>
<div class="menu-item"><a href="courses.html">Education & Honors</a></div>
<div class="menu-item"><a href="teaching.html">Teaching & Internship</a></div>
<div class="menu-item"><a href="activities.html">Activities</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Research Interests</h1>
</div>
<table class="imgtable"><tr><td>
<img src="photos/keywords2.png" alt="alt text" width="750px" height="307px" />&nbsp;</td>
<!-- <td align="left"><p> -->
<!-- <b>Perception Algorithms</b>:<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Two-Stage Region-based Object Detection<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Efficient Robotic Perception with Low Computation Consumption<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PointCloud-based 3D Object Detection<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Generative Object estimation Approaches<br />
<b>Other Technical Capabilities</b>:<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[New] Graphics Rendering and Scene Reconstruction<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Search-Based Robotic Path Planning<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Algorithm Design and Optimization<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Statistic System Modeling<br /> -->
<!-- <b>Technical Skills</b>:<br />
<br /> -->
<!-- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[New] Optimize Algorithm by Parallelization(CUDA)<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[New] Graphics Rendering and Scene Reconstruction<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Efficient Robotic Perception with Low Computation Consumption<br /> -->
<!-- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PointCloud-based 3D Object Detection<br /> -->
<!-- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Statistic System Modeling<br /> -->
<!-- &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Search-Based Robotic Path Planning<br /> -->
<!-- </p> -->
</td></tr></table>

<h1><BIG>M</BIG><small>ODEL</small> <BIG>B</BIG><small>ASED</small> <BIG>V</BIG><small>ISION</small></h1>

<h3>Outdoor Vehicle Detection | Advisor: Prof. Maxim Likhachev</h3>
<p>Research Staff, <i>Search-Based Planning Lab</i>&emsp;&emsp;&emsp;&emsp;<b>Robotics Institute, Carnegie Mellon University</b></p>
<ul>
<li><p>Proposed Vehicle-PERCH, a novel 3D vehicle detection framework that can detect vehicle 3D pose through an analysis-by-
synthesis manner. The algorithm effectively integrates 2D and 3D information, thus provides <b><em>REAL-TIME</em></b> capability</p></li>
<li><p>Applied unsupervised clustering method (Gaussian mixture models) to separate vehicles into twelve categories based on
vehicle size information, then constructed a dozen vehicle 3D models (microcar, sedan, compact car, SUV, etc.)</p></li>
<li><p>Experimented on the KITTI dataset. The results show that Vehicle-PERCH achieves <b><em>ON PAR</em></b> 3D detection & localization
performance with the state-of-the-art learning-based methods, <b><em>WITHOUT</em></b> using 3D pose annotation data</p></li>
<li><p>Submitted to ICRA 2021</p></li>
<video autoplay loop muted playsinline  width="640" height="360" autobuffer class="video-background" controls>
<!-- <video width="640" height="360" controls> -->
  <source src="photos/VPF.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
</ul>
<div class="infoblock">
<div class="blocktitle">Featured Publication:</div>
<div class="blockcontent">
<p><b>Yupeng Han</b>, Sandip Aine and Maxim Likhachev, "Real-time 3D Perception via Search for Vehicle Detection with No Pose Annotated Training Data", <i>IEEE International Conference on Robotics and Automation (ICRA) 2021</i>[Under Review]</p>
</div></div>


<h3>Indoor object 6DOF Pose Estimation |Advisor: Prof. Maxim Likhachev</h3>
<!-- Indoor 6-Dof Object Pose Estimation -->
<p>Research Staff, <i>Search-Based Planning Lab</i>&emsp;&emsp;&emsp;&emsp;<b>Robotics Institute, Carnegie Mellon University</b></p>
<ul>
<li><p>Studied Perception Via Search (PERCH) is a class of algorithms that is first rendering scenes with different object poses, then search for the best explanation of the observed scene in the space of possible rendered scenes, thus predict the object pose while accounting for occlusion</p>
</li>
<li>
  <p>
    Studied space rotation formalisms, took advantage of the object's geometric symmetry of the object to reduce redundant space rotation proposals, thereby achieving an algorithm speedup (over 50%)
  </p>
</li>
<li>
  <p>
    Tested on the open dataset (YCB), results show that our algorithm <b><em>SURPASSES</em></b> state-of-the-art 6-DOF pose estimation methods with remarkable margins without need for any ground truth pose annotations
  </p>
</li>
<!-- <li><p>Accepted by IROS 2020.</p></li> -->
<li><p>[<a href="https://arxiv.org/abs/2008.00326"> Paper</a>] | [<a href="https://sbpl-cruz.github.io/perception/"> Github</a>] | [<a href="https://www.youtube.com/watch?v=xNFWHj0rL6w"> Full Video Link</a>]</p></li>
<!-- <li><p></p></li>
<li><p></p></li> -->

<div>
    <!-- <img src="photos/pipeline.png" alt=""  width=579 height=320 />
    &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp -->
    <!-- 3132 × 1614 -->
    <!-- 2D and 3D Feature Fusion Video -->
    <!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/0YDGnGosKqw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->
    <!-- <video width="640" height="360" controls> -->
    <video autoplay loop muted playsinline  width="640" height="360" autobuffer class="video-background" controls>
      <source src="photos/perch2.mp4" type="video/mp4">
    Your browser does not support the video tag.
    </video>
</div>


<!-- <li><p>Details will release after the submission.</p>
</li> -->
<!-- <div>
    <img src="photos/pipeline.png" alt=""  width=620 height=321 />
</div> -->
</ul>
<div class="infoblock">
<div class="blocktitle">Featured Publication:</div>
<div class="blockcontent">
<p>Agarwal Aditya, <b>Han Yupeng</b>, and Maxim Likhachev, "PERCH 2.0 : Fast and Accurate GPU-based Perception via Search for Object Pose Estimation", <i>IEEE International Conference on Intelligent Robots and Systems 2020</i></p>
</div></div>




<h1><BIG>S</BIG><small>YSTEM</small> <BIG>A</BIG><small>NALYSIS</small></h1>
<h3>Modeling and Analysis of Complex System | Advisor: Prof. Jitesh Panchal</h3>
<p>Master Student, Design Engineering Lab at Purdue(DELP),&emsp;&emsp;&emsp;<b> ME Department, Purdue University</b></p>
<ul>
<li><p>Solved the difficulty of service seekers when faced with a large number of service providers, also addressed the drawbacks of the First In First Out (FIFO) matching mechanism by developed a stable matching system based on utility theory to generate the preference lists of service providers and service seekers. The matching mechanism was accomplished based on different utility interests. Searched for the optimal matching frequency using the provided matching.</p></li>
<!-- <li><p>Implemented the matching algorithm based on MATLAB and simulated service seekers arrive as a Poisson process with a fixed number of service providers offering resources. The service providers could only serve for one service seekers at one time.</p></li> -->
<!-- <li><p>[<a href="https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-abstract/IDETC-CIE2018/51722/V01AT02A024/273503">Paper</a>]</p></li> -->
</ul>
<div class="infoblock">
<div class="blocktitle">Featured Publication:</div>
<div class="blockcontent">
<p>Thekinen J., <b>Han Yupeng</b>, and Panchal J. H., "Designing market thickness and optimal frequency of multi-period stable matching in CBDM", <i>ASME International Design Engineering Technical Conferences Computers and Information in Engineering Conference 2018</i> [<a href="https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-abstract/IDETC-CIE2018/51722/V01AT02A024/273503">pdf</a>] <br /></p>
</div></div>















<h1>INTERESTING IDEAS</h1>

 <h3>2D and 3D Feature Fusion | Advisor: Prof. Cewu LU</h3>
<p>Machine Vision and Intelligence Group, CS Department, SJTU</p>
<ul>
<li><p>Aiming to use one neural network to detect multi-scale objects by applying different anchors to different categories</p></li>
<!-- <li><p>Explored using a single model makes 3D detection in multi-scale objects; generated ideas to strengthen the 3D point cloud and extracted features by utilizing 2D RGB extracted features and dynamic anchor boxes&rsquo; size determined by 2D images.</p></li> -->
<li><p>Built the pipeline of the fusion network, including extracting different features from point clouds and RGB images, transforming 2D information to 3D proposal boxes, cropped key points and their 3D features inside the proposal boxes, and concatenated 3D features with 2D features, and performed post-processing.</p></li>
<!-- <li><p>Implemented a modified version of Faster-RCNN from scripts to feed in RGB images and output bounding boxes, classification labels, estimated depths, and proposal orientations in bird&ndash;eye view -– this project had over 6k lines of code.</p></li> -->
<!-- <li><p>Selected the sparse convolution network as the backbone of the 3D point cloud feature extractor due to its performance on ScanNet.</p></li> -->
<li><p>[<a href="https://github.com/YupengHan/FusionNet">Github</a>]</p>
</li>
<div>
    <!-- <img src="photos/fusion.png" alt=""  width=538 height=336 />
    &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp -->
    <video width="538" height="336" controls>
        <source src="photos/2D3Dfusion.mp4" type="video/mp4">
    Your browser does not support the video tag.
    </video>
</div> 
</ul>
<h3>Data-Aware Algorithm to Solve Discrete Integration | Advisor: Prof. Yexiang Xue</h3>
<p>Machine Learning Group, CS Department, Purdue University</p>
<ul>
<li><p>Inspired by &ldquo;Taming the Curse of Dimensionality: Discrete Integration by Hashing and Optimization&rdquo; and exploited a data-aware strategy to modify the original algorithm.</p>
</li>
<li><p>Generated an adaptive comparison strategy to reduce the expectation of computational complexity without loss of constant estimation guarantee and compared to the new algorithm with an imaginary &ldquo;optimal&rdquo; algorithm to provide a regret bound for the new algorithm.</p>
</li>
<li><p>[<a href="algorithm_design.pdf">Manuscripts</a>] | [<a href="https://drive.google.com/open?id=1ebdHFkPVb7xPHdFYmMZG4JlAzdwkPzxv">Presentation Slides</a>]</p>
</li>
<div class="image"/><br />
<div>
    <img src="gifs/PI1.gif" alt=""  width=550 height=309 />
    &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
    <img src="gifs/PI2.gif" alt=""  width=550 height=309 />
</div>
</ul>
<!-- <h2>Social Network Analysis | Advisor: Prof. David F. Gleich</h2>
<p>Social Network Analysis | Advisor: Prof. David F. Gleich, CS Department, Purdue University</p>
<ul>
<li><p>Read Ego-splitting from previous paper which is a highly scalable and flexible framework that reduces the complex overlapping clustering problem to a more straightforward and more amenable non-overlapping partitioning problem.</p>
</li>
<li><p>Re-accomplished the Ego-splitting framework in Julia. The new framework could handle a large graph (millions of edges) within a few (less than 10) minutes.</p>
</li>
<li><p>Demo of how Ego-splitting works, nodes stands for people, and edges stands for relationship. Nodes #1 is Yupeng HAN, nodes #2, #3, #4 are Yupeng's shoolmates, nodes #8, #9, #10 are Yupeng's co-workers and nodes #5, #6, #7 are Yupeng's family members. To better analysis the social network, we can divide Yupeng in to three nodes, #1, #11, #12 to represent Yupeng's working, studying, home characters. Following are the demo and the result of the efficiency. </p>
</li>
<li><p>[<a href="https://github.com/YupengHan/Ego-splitting-in-Julia">GitHub</a>]</p>
</li>
</ul>
<table class="imgtable"><tr><td>
<img src="photos/ego_split_demo.png" alt="alt text" width="930px" height="250px" />&nbsp;</td>
<td align="left"></td></tr></table>
<table class="imgtable"><tr><td>
<img src="photos/ego_split_result.png" alt="alt text" width="930px" height="290px" />&nbsp;</td>
<td align="left"></td></tr></table> -->
<a href="projects.html"><i>Some Interesting Projects~</i></a>
</td>
</tr>
</table>
</body>
</html>


























<!-- <h2>GPU-based Perception via Search for Vehicle Detection |Advisor: Prof. Maxim Likhachev</h2>
<p>Research Assistant, Search-Based Planning Lab, <b>The Robotics Institute, Carnegie Mellon University</b></p>
<ul>
<li><p> -->
<!-- Noticed the distinct advantages of detecting occluded objects with generative approaches that estimated the pose of every object in the scene by constantly reconstructing the scene and evaluating the difference between the reconstructed scene and the input scene. -->
<!-- Propose an accurate, robust, and real-time framework target to solve 3D vehicle detection problems. -->
<!-- Overcome the efficiency problem of 2D \& 3D feature fusion.
Learning-Free Framework that can accurately estimate vehicle 3D pose from the 2D bounding box with real-time performance. -->
<!-- </p>
<li><p>
Propose a novel way of aggregation the 2D & 3D information aiming to mitigate the occlusion caused double the viewpoints(LiDAR lens viewpoint and camera lens viewpoint) -->
<!-- Enhanced robotic perception performance under especially poor visual conditions by bridging the generative approaches with learning-based perception and prior knowledge embedded in the probabilistic graphical model. -->
<!-- </p>
</li>
<li>
<p> -->
<!-- Covered state-of-the-art probabilistic graphical models to explore the possibility of embedding prior knowledge into those models. -->
<!-- Learning-Free pipeline that can accurately estimate object 3D pose from 2D bounding box on RGB image.
</p>
</li>
<li>
<p>
Through GPU-based parallelization, the algorithm can obtain real-time processing capabilities. -->
<!-- Tested generative approaches with multiple evaluation functions and utilized prior data, such as number of cars on the road, to reduce the number of reconstructed scenes significantly; Experimented on 3D object detection task of KITTI Dataset. -->
<!-- </p>
</li>
<li>
<p>
Experiments on the KITTI dataset and achive good accuracy without the need of 3D pose annotation.
</p>
</li>
<li>
<p>[Ongoing Project] Going to submit to ICRA 2021</p>
</li> -->
<!-- Perception by Generation Videos 1274 × 720-->
<!-- <video width="637" height="360" controls>
  <source src="photos/PBG_outdoor.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>

</ul> -->